{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import model\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, h1_dim, h2_dim, h3_dim, device):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm_cell_1 = nn.LSTMCell(input_dim, h1_dim)\n",
    "        self.lstm_cell_2 = nn.LSTMCell(h1_dim, h2_dim)\n",
    "        self.lstm_cell_3 = nn.LSTMCell(h2_dim, h3_dim)\n",
    "        self.input_dim = input_dim\n",
    "        self.h1_dim = h1_dim\n",
    "        self.h2_dim = h2_dim\n",
    "        self.h3_dim = h3_dim\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h1, c1 = torch.zeros((input_seq.shape[1], self.h1_dim)).to(self.device), torch.zeros((input_seq.shape[1], self.h1_dim)).to(self.device)\n",
    "        h2, c2 = torch.zeros((input_seq.shape[1], self.h2_dim)).to(self.device), torch.zeros((input_seq.shape[1], self.h2_dim)).to(self.device)\n",
    "        h3, c3 = torch.zeros((input_seq.shape[1], self.h3_dim)).to(self.device), torch.zeros((input_seq.shape[1], self.h3_dim)).to(self.device)\n",
    "        for i in range(len(input_seq)):\n",
    "            h1, c1 = self.lstm_cell_1(input_seq[i], (h1, c1))\n",
    "            h2, c2 = self.lstm_cell_2(h1, (h2, c2))\n",
    "            h3, c3 = self.lstm_cell_3(h2, (h3, c3))\n",
    "        return h1, c1, h2, c2, h3, c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = torch.load('/Users/reza/Downloads/models/m1_enc.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc.state_dict(), './m1_enc_state.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=128, in_channels=1, out_channels=4, latent_dim=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding='same')\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, out_channels * 2, 3, padding='same')\n",
    "        self.flatten_dim = (input_dim // 4) ** 2 * out_channels * 2\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, self.flatten_dim//4)\n",
    "        self.fc2 = nn.Linear(self.flatten_dim//4, latent_dim)\n",
    "        self.max = nn.MaxPool2d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max(x)\n",
    "        x = x.view(-1, self.flatten_dim)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = torch.load('/Users/reza/Downloads/models/m2_enc.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc.state_dict(), './m2_enc_state.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = torch.load('/Users/reza/Downloads/models/m3_enc.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc.state_dict(), './m3_enc_state.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
